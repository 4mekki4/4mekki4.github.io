---
title: "BERT-based multi-task model for country and province level MSA and dialectal Arabic identification"
category: articles
permalink: /articles/2021-04-12-nadi-bert-multi-task
excerpt: '<b>Abdellah El Mekki</b>, Abdelkader El Mahdaouy, Kabil Essefar, Nabil El Mamoun, Ismail Berrada, Ahmed Khoumsi'
date: 2021-04-12
venue: 'Proceedings of the Sixth Arabic Natural Language Processing Workshop'
citation: '[BERT-based Multi-Task Model for Country and Province Level MSA and Dialectal Arabic Identification](https://aclanthology.org/2021.wanlp-1.31) (El Mekki et al., WANLP 2021)'
---

<a href='https://aclanthology.org/2021.wanlp-1.31.pdf'>Download PDF here</a>

Abstract: Dialect and standard language identification are crucial tasks for many Arabic natural language processing applications. In this paper, we present our deep learning-based system, submitted to the second NADI shared task for country-level and province-level identification of Modern Standard Arabic (MSA) and Dialectal Arabic (DA). The system is based on an end-to-end deep Multi-Task Learning (MTL) model to tackle both country-level and province-level MSA/DA identification. The latter MTL model consists of a shared Bidirectional Encoder Representation Transformers (BERT) encoder, two task-specific attention layers, and two classifiers. Our key idea is to leverage both the task-discriminative and the inter-task shared features for country and province MSA/DA identification. The obtained results show that our MTL model outperforms single-task models on most subtasks.


 Recommended citation: [BERT-based Multi-Task Model for Country and Province Level MSA and Dialectal Arabic Identification](https://aclanthology.org/2021.wanlp-1.31) (El Mekki et al., WANLP 2021)